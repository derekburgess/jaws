{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import asyncio\n",
    "from typing import Annotated\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import(\n",
    "    ChatCompletionAgent, \n",
    "    GroupChatOrchestration, \n",
    "    RoundRobinGroupChatManager, \n",
    "    OrchestrationHandoffs, \n",
    "    HandoffOrchestration, \n",
    "    ConcurrentOrchestration\n",
    ")\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings, OpenAIChatCompletion\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from datetime import datetime, timedelta\n",
    "from jaws.jaws_config import *\n",
    "from jaws.jaws_utils import dbms_connection\n",
    "\n",
    "# Database not passed, uses the database set in jaws_config.py\n",
    "driver = dbms_connection(DATABASE)\n",
    "kernel = Kernel()\n",
    "settings = OpenAIChatPromptExecutionSettings()\n",
    "reasoning_service = OpenAIChatCompletion(ai_model_id=OPENAI_REASONING_MODEL, api_key=OPENAI_API_KEY)\n",
    "kernel.add_service(reasoning_service)\n",
    "lang_service = OpenAIChatCompletion(ai_model_id=OPENAI_MODEL, api_key=OPENAI_API_KEY)\n",
    "kernel.add_service(lang_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "class ListInterfaces:\n",
    "    @kernel_function(description=\"List available network interfaces. You will never want to select interfaces such as; 'lo' and 'docker0'\")\n",
    "    def list_interfaces(self) -> Annotated[str, \"A list of available network interfaces.\"]:\n",
    "        interfaces = subprocess.run(['python', './jaws/jaws_capture.py', '--list', '--agent'], capture_output=True, text=True)\n",
    "        return str(interfaces.stdout)\n",
    "\n",
    "\n",
    "class CapturePackets:\n",
    "    @kernel_function(description=\"Captures packets into the database. Choose a duration depending on the amount of data you want to capture. Recommended not to exceed 60 seconds.\")\n",
    "    def capture_packets(self, interface: str, duration: int) -> Annotated[str, \"A process status message once the process is complete.\"]:\n",
    "        if duration > 60:\n",
    "            duration = 60\n",
    "        packets = subprocess.run(['python', './jaws/jaws_capture.py', '--interface', interface, '--duration', str(duration), '--agent'], capture_output=True, text=True)\n",
    "        return str(packets.stdout)\n",
    "\n",
    "\n",
    "class DocumentOrganizations:\n",
    "    @kernel_function(description=\"Enriches data with organization ownership by looking up IP addresses.\")\n",
    "    def document_organizations(self) -> Annotated[str, \"A process status message once the process is complete.\"]:\n",
    "        organizations = subprocess.run(['python', './jaws/jaws_ipinfo.py', '--agent'], capture_output=True, text=True)\n",
    "        return str(organizations.stdout)\n",
    "\n",
    "\n",
    "class ComputeEmbeddings:\n",
    "    @kernel_function(description=\"Transforms the network traffic data into embeddings for analysis.\")\n",
    "    def compute_embeddings(self) -> Annotated[str, \"A process status message once the process is complete.\"]:\n",
    "        embeddings = subprocess.run(['python', './jaws/jaws_compute.py', '--agent'], capture_output=True, text=True)\n",
    "        return str(embeddings.stdout)\n",
    "    \n",
    "\n",
    "class AnomalyDetection:\n",
    "    @kernel_function(description=\"Analyzes the network traffic data and embeddings and returns a list of anomalies.\")\n",
    "    def anomoly_detection(self) -> Annotated[str, \"A string containing a list of anomalies.\"]:\n",
    "        output = subprocess.run(['python', './jaws/jaws_finder.py', '--agent'], capture_output=True, text=True)\n",
    "        return str(output.stdout)\n",
    "    \n",
    "\n",
    "class FetchData:\n",
    "    @kernel_function(description=\"Fetches the latest (10 minutes) traffic data from the database and returns it as a string.\")\n",
    "    def fetch_traffic(self) -> Annotated[str, \"A string containing a list of current traffic data.\"]:\n",
    "        query = \"\"\"\n",
    "        MATCH (traffic:TRAFFIC)\n",
    "        WHERE traffic.TIMESTAMP > datetime() - duration({minutes: 10})\n",
    "        RETURN DISTINCT\n",
    "            traffic.IP_ADDRESS AS ip_address,\n",
    "            traffic.PORT AS port,\n",
    "            traffic.ORGANIZATION AS org,\n",
    "            traffic.HOSTNAME AS hostname,\n",
    "            traffic.LOCATION AS location,\n",
    "            traffic.TOTAL_SIZE AS total_size,\n",
    "            traffic.OUTLIER AS outlier,\n",
    "            traffic.TIMESTAMP AS timestamp\n",
    "        ORDER BY traffic.TIMESTAMP DESC\n",
    "        LIMIT 100\n",
    "        \"\"\"\n",
    "        with driver.session(database=DATABASE) as session:\n",
    "            result = session.run(query)\n",
    "            data = []\n",
    "            for record in result:\n",
    "                data.append({\n",
    "                    'ip_address': record['ip_address'],\n",
    "                    'port': record['port'],\n",
    "                    'org': record['org'],\n",
    "                    'hostname': record['hostname'],\n",
    "                    'location': record['location'],\n",
    "                    'total_size': record['total_size'],\n",
    "                    'outlier': record['outlier'],\n",
    "                    'timestamp': record['timestamp']\n",
    "                })\n",
    "            return str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "operator_0 = ChatCompletionAgent(\n",
    "    service=lang_service,\n",
    "    name=\"Operator0\",\n",
    "    description=\"You are the eyes of the network. You are tasked with sampling and reviewing network traffic data to identify patterns, anomalies, escalating to Lead Analyst and their team for further probing and reporting up the chain.\",\n",
    "    instructions=OPERATOR_PROMPT,\n",
    "    plugins=[ListInterfaces(), CapturePackets(), DocumentOrganizations(), ComputeEmbeddings(), AnomalyDetection()],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "operator_1 = ChatCompletionAgent(\n",
    "    service=lang_service,\n",
    "    name=\"Operator1\",\n",
    "    description=\"You are the eyes of the network. You are tasked with sampling and reviewing network traffic data to identify patterns, anomalies, escalating to Lead Analyst and their team for further probing and reporting up the chain.\",\n",
    "    instructions=OPERATOR_PROMPT,\n",
    "    plugins=[ListInterfaces(), CapturePackets(), DocumentOrganizations(), ComputeEmbeddings(), AnomalyDetection()],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "network_analyst = ChatCompletionAgent(\n",
    "    service=lang_service, \n",
    "    name=\"NetworkAnalyst\",\n",
    "    description=\"An expert IT Professional, Sysadmin, and Analyst. Tasked with capturing network packets and performing ETL(Extract, Transform, and Load) with the data to prepare it for analysis.\",\n",
    "    instructions=ANALYST_MANAGED_PROMPT,\n",
    "    plugins=[ListInterfaces(), CapturePackets(), DocumentOrganizations(), ComputeEmbeddings()],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "lead_network_analyst = ChatCompletionAgent(\n",
    "    service=reasoning_service,\n",
    "    name=\"LeadAnalyst\",\n",
    "    description=\"An expert IT Professional, Sysadmin, and Analyst. Tasked with reviewing network traffic data to identify patterns, anomalies, and make recommendations for security configurations.\",\n",
    "    instructions=MANAGER_PROMPT,\n",
    "    plugins=[AnomalyDetection(), FetchData()],\n",
    "    arguments=KernelArguments(settings)\n",
    ")\n",
    "\n",
    "handoffs = (\n",
    "    OrchestrationHandoffs()\n",
    "    .add(\n",
    "        source_agent=operator_0.name,\n",
    "        target_agent=lead_network_analyst.name,\n",
    "        description=\"The operator collects short 10-30 second snapshots of network traffic data, analyzes the data for anomalies, and returns a list of red flags to the Lead Analyst.\",\n",
    "    )\n",
    "    .add(\n",
    "        source_agent=lead_network_analyst.name,\n",
    "        target_agent=network_analyst.name,\n",
    "        description=\"The Lead Analyst reviews the Operator's list of red flags and requests an additional 30-60 seconds of network traffic data from the Network Analyst to support the Lead Analyst's final report.\",\n",
    "    )\n",
    "    .add(\n",
    "        source_agent=network_analyst.name,\n",
    "        target_agent=lead_network_analyst.name,\n",
    "        description=\"The Network Analyst informs the Lead Analyst when the capture and ETL tasks are complete. The Lead Analyst will then review the data and return a moderately detailed report to the command center.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orchestration(s)\n",
    "concurrent_members=[operator_0, operator_1]\n",
    "handoff_members=[operator_0, lead_network_analyst, network_analyst]\n",
    "group_members=[network_analyst, lead_network_analyst]\n",
    "max_rounds = 2\n",
    "\n",
    "\n",
    "def human_response_function() -> ChatMessageContent:\n",
    "    message = \"No human response required.\"\n",
    "    return ChatMessageContent(role=AuthorRole.USER, content=message)\n",
    "\n",
    "\n",
    "async def agent_callback(message: ChatMessageContent) -> None:\n",
    "    for item in message.items or []:\n",
    "        if isinstance(item, FunctionCallContent):\n",
    "            print(f\"Function Call:> {item.name} with arguments: {item.arguments}\")\n",
    "        elif isinstance(item, FunctionResultContent):\n",
    "            print(f\"Function Result:> {item.result} for function: {item.name}\")\n",
    "        else:\n",
    "            print(f\"{message.name}: {message.content}\")\n",
    "\n",
    "\n",
    "async def concurrent_orchestration(input: str) -> str:\n",
    "    orchestration_config = ConcurrentOrchestration(members=concurrent_members)\n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "\n",
    "    print(f\"[INPUT] | {input}\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"[ORCHESTRATION] | [CONCURRENT] {len(concurrent_members)}\")\n",
    "        result = await orchestration_config.invoke(\n",
    "            task=input,\n",
    "            runtime=runtime\n",
    "        )\n",
    "        \n",
    "        response = await result.get()\n",
    "\n",
    "        response_collection = []\n",
    "        for item in response:\n",
    "            response_collection.append(f\"{item.name}: {item.content}\")\n",
    "\n",
    "        response_text = str(\"\\n\".join(response_collection))\n",
    "        print(f\"[RESPONSE] |\\n{response_text}\")\n",
    "        return response_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] | {e}\")\n",
    "        return f\"[ERROR] | {e}\"\n",
    "        \n",
    "    finally:\n",
    "        await runtime.stop_when_idle()\n",
    "        \n",
    "\n",
    "async def handoff_orchestration(input: str) -> str:\n",
    "    orchestration_config = HandoffOrchestration(\n",
    "        members=handoff_members,\n",
    "        handoffs=handoffs,\n",
    "        agent_response_callback=agent_callback,\n",
    "        human_response_function=human_response_function\n",
    "    )\n",
    "    \n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "\n",
    "    print(f\"[INPUT] | {input}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"[ORCHESTRATION] | [HANDOFF] {len(handoff_members)}\")\n",
    "        result = await orchestration_config.invoke(\n",
    "            task=input,\n",
    "            runtime=runtime,\n",
    "        )\n",
    "        \n",
    "        response = await result.get()\n",
    "        response_text = response.content\n",
    "        print(f\"[RESPONSE] | {response_text}\")\n",
    "        return response_text\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] | {e}\")\n",
    "        return f\"[ERROR] | {e}\"\n",
    "        \n",
    "    finally:\n",
    "        await runtime.stop_when_idle()\n",
    "\n",
    "\n",
    "async def group_orchestration(input: str) -> str:\n",
    "    orchestration_config = GroupChatOrchestration(\n",
    "        members=group_members,\n",
    "        manager=RoundRobinGroupChatManager(max_rounds=max_rounds),\n",
    "        agent_response_callback=agent_callback\n",
    "    )\n",
    "\n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "\n",
    "    print(f\"[INPUT] | {input}\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"[ORCHESTRATION] | [GROUP CHAT] {len(group_members)} | [ROUND ROBIN] {max_rounds}\")\n",
    "        result = await orchestration_config.invoke(\n",
    "            task=input,\n",
    "            runtime=runtime\n",
    "        )\n",
    "        \n",
    "        response = await result.get()\n",
    "        response_text = response.content\n",
    "        print(f\"[RESPONSE] | {response_text}\")\n",
    "        return response_text\n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] | {e}\")\n",
    "        return f\"[ERROR] | {e}\"\n",
    "        \n",
    "    finally:\n",
    "        await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface\n",
    "def next_report(minutes):\n",
    "    next_report_time = datetime.now() + timedelta(minutes=minutes)\n",
    "    return f\"⏲️ Automatic Report | {minutes} Minutes | {next_report_time.strftime('%H:%M:%S')}\"\n",
    "\n",
    "\n",
    "with gr.Blocks(title=\"Network Traffic Monitoring\") as INTERFACE:\n",
    "    concurrent_minutes = gr.State(value=15)\n",
    "    concurrent_seconds = gr.State(value=concurrent_minutes.value * 60)\n",
    "    concurrent_timer = gr.Timer(value=concurrent_seconds.value, active=True)\n",
    "    concurrent_chat_history = gr.State(value=[{\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"A group of operators tasked with capturing short 10-30 second snapshots of network traffic and returning a list of potential red flags to the command center.\",\n",
    "        \"metadata\": {\"title\": \"👁️ Traffic Overwatch\"}\n",
    "    }])\n",
    "\n",
    "    handoff_minutes = gr.State(value=30)\n",
    "    handoff_seconds = gr.State(value=handoff_minutes.value * 60)\n",
    "    handoff_timer = gr.Timer(value=handoff_seconds.value, active=True)\n",
    "    handoff_chat_history = gr.State(value=[{\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"A managed group of network analysts tasked with capturing 30-60 second snapshots of network traffic data, enchring the data, and returning a moderately detailed situational report to the command center.\",\n",
    "        \"metadata\": {\"title\": \"🔎 Traffic Analysis\"}\n",
    "    }])\n",
    "\n",
    "    groupchat_minutes = gr.State(value=30) # NOT IN USE\n",
    "    groupchat_seconds = gr.State(value=groupchat_minutes.value * 60)\n",
    "    groupchat_timer = gr.Timer(value=groupchat_seconds.value, active=True)\n",
    "    groupchat_history = gr.State(value=[{\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": \"A collaborative group of analysts tasked with capturing 30-60 second snapshots of network traffic data, enchring the data, and returning a comprehensive report for the high command.\",\n",
    "        \"metadata\": {\"title\": \"🪬 Command Center\"}\n",
    "    }])\n",
    "    \n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column():\n",
    "            concurrent_chatbot = gr.Chatbot(\n",
    "                value=concurrent_chat_history.value,\n",
    "                type=\"messages\",\n",
    "                show_label=True,\n",
    "                label=\"CONCURRENT\",\n",
    "                autoscroll=True,\n",
    "                resizable=True,\n",
    "                show_copy_button=True,\n",
    "                height=480\n",
    "            )\n",
    "            concurrent_timer_status = gr.Textbox(\n",
    "                value=next_report(concurrent_minutes.value),\n",
    "                #value=\"No automatic report scheduled.\",\n",
    "                show_label=False,\n",
    "                container=False,\n",
    "                interactive=False,\n",
    "                text_align=\"center\"\n",
    "            )\n",
    "            concurrent_request_button = gr.Button(\"💬 Request Team Report In\", variant=\"huggingface\")\n",
    "    \n",
    "        with gr.Column():\n",
    "            handoff_chatbot = gr.Chatbot(\n",
    "                value=handoff_chat_history.value,\n",
    "                type=\"messages\",\n",
    "                show_label=True,\n",
    "                label=\"HANDOFF\",\n",
    "                autoscroll=True,\n",
    "                resizable=True,\n",
    "                show_copy_button=True,\n",
    "                height=480\n",
    "            )\n",
    "            handoff_timer_status = gr.Textbox(\n",
    "                value=next_report(handoff_minutes.value),\n",
    "                #value=\"No automatic report scheduled.\",\n",
    "                show_label=False,\n",
    "                container=False,\n",
    "                interactive=False,\n",
    "                text_align=\"center\"\n",
    "            )\n",
    "            handoff_request_button = gr.Button(\"💬 Request Team Report In\", variant=\"huggingface\")\n",
    "    \n",
    "        with gr.Column():\n",
    "            groupchat_chatbot = gr.Chatbot(\n",
    "                value=groupchat_history.value,\n",
    "                type=\"messages\",\n",
    "                show_label=True,\n",
    "                label=\"GROUPCHAT\",\n",
    "                autoscroll=True,\n",
    "                resizable=True,\n",
    "                show_copy_button=True,\n",
    "                height=480\n",
    "            )\n",
    "            groupchat_timer_status = gr.Textbox(\n",
    "                #value=next_report(groupchat_minutes.value),\n",
    "                value=\"No automatic report scheduled.\",\n",
    "                show_label=False,\n",
    "                container=False,\n",
    "                interactive=False,\n",
    "                text_align=\"center\"\n",
    "            )\n",
    "            groupchat_request_button = gr.Button(\"💬 Request Team Report In\", variant=\"huggingface\")\n",
    "\n",
    "    async def run_concurrent(history):\n",
    "        response = await concurrent_orchestration(\"Perform a short 10-30 second network probe and report back to the command center ASAP.\")\n",
    "        timestamp = datetime.now()\n",
    "        formatted_response = {\"role\": \"assistant\", \"content\": response, \"metadata\": {\"title\": f\"️🚩 Red Flag Report | {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\"}}\n",
    "        chat_history = (history + [formatted_response])[-10:]\n",
    "        return chat_history, chat_history\n",
    "    \n",
    "    async def run_handoff(history):\n",
    "        response = await handoff_orchestration(\"Perform a 30-60 second network scan and report back the findings to the command center ASAP.\")\n",
    "        timestamp = datetime.now()\n",
    "        formatted_response = {\"role\": \"assistant\", \"content\": response, \"metadata\": {\"title\": f\"️📋 Situation Report | {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\"}}\n",
    "        chat_history = (history + [formatted_response])[-3:]\n",
    "        return chat_history, chat_history\n",
    "    \n",
    "    async def run_groupchat(history):\n",
    "        response = await group_orchestration(\"High command is requesting the comprehensive network traffic report ASAP.\")\n",
    "        timestamp = datetime.now()\n",
    "        formatted_response = {\"role\": \"assistant\", \"content\": response, \"metadata\": {\"title\": f\"🛡️ Briefing for High Command | {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\"}}\n",
    "        chat_history = (history + [formatted_response])[-3:]\n",
    "        return chat_history, chat_history\n",
    "\n",
    "    concurrent_timer.tick(\n",
    "        fn=run_concurrent,\n",
    "        inputs=[concurrent_chat_history],\n",
    "        outputs=[concurrent_chatbot, concurrent_chat_history]\n",
    "    )\n",
    "    \n",
    "    concurrent_timer.tick(\n",
    "        fn=next_report,\n",
    "        inputs=[concurrent_minutes],\n",
    "        outputs=[concurrent_timer_status]\n",
    "    )\n",
    "\n",
    "    concurrent_request_button.click(\n",
    "        fn=run_concurrent,\n",
    "        inputs=[concurrent_chat_history],\n",
    "        outputs=[concurrent_chatbot, concurrent_chat_history]\n",
    "    )\n",
    "\n",
    "    handoff_timer.tick(\n",
    "        fn=run_handoff,\n",
    "        inputs=[handoff_chat_history],\n",
    "        outputs=[handoff_chatbot, handoff_chat_history]\n",
    "    )\n",
    "    \n",
    "    handoff_timer.tick(\n",
    "        fn=next_report,\n",
    "        inputs=[handoff_minutes],\n",
    "        outputs=[handoff_timer_status]\n",
    "    )\n",
    "\n",
    "    handoff_request_button.click(\n",
    "        fn=run_handoff,\n",
    "        inputs=[handoff_chat_history],\n",
    "        outputs=[handoff_chatbot, handoff_chat_history]\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    groupchat_timer.tick(\n",
    "        fn=run_groupchat,\n",
    "        inputs=[groupchat_history],\n",
    "        outputs=[groupchat_chatbot, groupchat_history]\n",
    "    )\n",
    "    \n",
    "    groupchat_timer.tick(\n",
    "        fn=next_report,\n",
    "        inputs=[handoff_minutes],\n",
    "        outputs=[handoff_timer_status]\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    groupchat_request_button.click(\n",
    "        fn=run_groupchat,\n",
    "        inputs=[groupchat_history],\n",
    "        outputs=[groupchat_chatbot, groupchat_history]\n",
    "    )\n",
    "\n",
    "INTERFACE.launch() #share=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
